#!/usr/bin/env python3

from bs4 import BeautifulSoup as soup #install with 'pip install BeautifulSoup4
import json


#making the http request 
import requests #reference: https://realpython.com/python-requests/
response = requests.get("https://www.sephora.com/shop/hair-products", headers={'User-Agent':'Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0'})

print(response.text)

#quit(run was successful)

headers = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Methods': 'GET',
    'Access-Control-Allow-Headers': 'Content-Type',
    'Access-Control-Max-Age': '3600',
    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0'
    }

#opening up connection grabbing the page'
url_to_scrape = "https://www.sephora.com/shop/hair-products"

#download a webpage with a user agent other than the default one
page_html = request_page.read() #offloads the content into a variable
request.page() #closes
page_soup = soup (page_html,'html.parser') # Creating the Soup Object containing all data

data = json.loads(soup.find('script', id='linkJSON').text)
products = data[3]['props']['products'] #how you get data in list/dictionary in Python json.loads convert the JSON data to Python's data structure

prefix = "https://www.sephora.com"

url_links = [prefix+p["targetUrl"] for p in products]
print(url_links)

#gather the data from the pages to form the csv

#find all div and feed it the object and grabs each product
sephora_items = page_soup.findAll('div',{'class': "ProductTile-name css-h8cc3p eanm77i0"})

filename = "products.csv"
f = open(filename, 'w')

headers = "Title, Price /n"

f.write(headers)

for sephora in sephora_items:
    title = sephora.find ('div', {'class': "css-bpsjlq eanm77i0"}).text
    price = sephora.find ('div', {'class': "css-0"}).text

#concatenate them together
    f.write(title + ',' + price)

f.close()
